# -*- coding: utf-8 -*-
"""Proyek Deep Learning Yusep.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dwNJGtQbYJNAcNgpUZkMkTvrzXme7iR-

# Import Library
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error
import yfinance as yf

"""# Data Collection"""

df = yf.download('UNVR.JK', start='2005-01-01', end='2025-01-01')
df.index.name = 'Date'

df.info()

"""# Data Preprocessing"""

plt.figure(figsize=(14,5))
plt.plot(df['Close'], label='Harga Penutupan', color='blue')
plt.title('Harga Saham UNILEVER')
plt.ylabel('Harga (IDR)')
plt.legend()
plt.grid(True)
plt.show()


ms = MinMaxScaler()
df['Close_ms'] = ms.fit_transform(df[['Close']])

train_size = 0.8
size = int(len(df) * train_size)
train, test = df['Close_ms'].iloc[:size], df['Close_ms'].iloc[size:]

"""# Feature Engineering"""

def split_target(data, look_back=1):
    X, y = [], []
    for i in range(len(data) - look_back):
        X.append(data[i:(i + look_back)])
        y.append(data[i + look_back])
    return np.array(X), np.array(y)

look_back = 1
X_train, y_train = split_target(train.values, look_back)
X_test, y_test = split_target(test.values, look_back)
X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))
X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))

"""# Model Selection"""

model = Sequential([
    LSTM(128, input_shape=(1, look_back), return_sequences=True),
    Dropout(0.2),
    LSTM(64),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(1)
])

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
              loss=tf.keras.losses.Huber(),
              metrics=['mae'])

"""# Model Training"""

history = model.fit(X_train, y_train, epochs=200, batch_size=32,
                    validation_data=(X_test, y_test), shuffle=False,
                    callbacks=[EarlyStopping(monitor='val_mae', patience=10)])

"""# Model Evaluation"""

plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'], label='Loss', color='blue')
plt.plot(history.history['val_loss'], label='Validation Loss', color='red')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.grid(True)
plt.show()


pred = model.predict(X_test)
y_pred = np.array(pred).reshape(-1)


mae = mean_absolute_error(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred) ** 0.5
mape = mean_absolute_percentage_error(y_test, y_pred)
print(f'MAE: {mae}, RMSE: {rmse}, MAPE: {mape}')

"""# Prediction"""

plt.figure(figsize=(15, 7))
plt.plot(test.index[:-1], y_test, label='Actual')
plt.plot(test.index[:-1], y_pred, label='Predicted')
plt.xlabel('Date')
plt.ylabel('Stock Price (Scaled)')
plt.title('Stock Price Prediction UNILEVER LSTM')
plt.legend()
plt.show()